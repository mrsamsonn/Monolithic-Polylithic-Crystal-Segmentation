{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b998e2-1dbe-4060-b1df-1ad853f34707",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6f84f-8589-4302-8d03-5fac6652121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import stempy.io as stio\n",
    "import stempy.image as stim\n",
    "import h5py\n",
    "import ncempy\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.colors import LogNorm, PowerNorm\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import rgb2lab, rgb2gray\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import filters, morphology, segmentation as seg\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02d18d-a3cf-41e8-85fb-b37488e48df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize\n",
    "class GridSegmentation:\n",
    "    def __init__(self, bf, sp, gif_counter=0, is_gif=False, block_size=11, clusters=0, mask_threshold=0.5,\n",
    "                 max_k_clusters=15, threshold=0.2, sigma=5, peak_square_size=11, real_bg_sigma=7, peak_threshold = 2, facecolor_visible=0,\n",
    "                 edge_points=0, intensity_weight=1, plot_dp_log=True, print_cluster_boxes=True):\n",
    "\n",
    "        #main variables\n",
    "        self.bf = bf\n",
    "        self.sp = sp\n",
    "        self.gif_counter = gif_counter\n",
    "        self.is_gif = is_gif\n",
    "        self.block_size = block_size\n",
    "        self.clusters = clusters\n",
    "        self.max_k_clusters = max_k_clusters\n",
    "        self.threshold = threshold\n",
    "        self.sigma = sigma\n",
    "        self.edge_points = edge_points\n",
    "        self.plot_dp_log = plot_dp_log\n",
    "        self.print_cluster_boxes = print_cluster_boxes\n",
    "        self.intensity_weight = intensity_weight\n",
    "        self.peak_square_size = peak_square_size\n",
    "        self.real_bg_sigma = real_bg_sigma\n",
    "        self.peak_threshold = peak_threshold\n",
    "        self.mask_threshold = mask_threshold\n",
    "        self.facecolor_visible = facecolor_visible\n",
    "\n",
    "        #total number of blocks in terms of block size in real space    \n",
    "        self.num_blocks_x = bf.shape[0] // block_size\n",
    "        self.num_blocks_y = bf.shape[1] // block_size\n",
    "\n",
    "        #stores coordinates x1 x2 y1 y2 of each block\n",
    "        self.block_coordinates = []\n",
    "    \n",
    "        #corresponding dp for valid blocks in real space\n",
    "        self.valid_dp_logs = []\n",
    "        \n",
    "        #used to group valid dp by cluster\n",
    "        self.clustered_data = {}\n",
    "\n",
    "        self.peak_locations = []\n",
    "\n",
    "        #stores calculated similarity and corresponding real space indices used for clustering\n",
    "        self.features = np.zeros((len(self.valid_dp_logs), len(self.peak_locations) + 1))\n",
    "\n",
    "        self.rs_mask = np.zeros(self.bf.shape, dtype=np.bool_)\n",
    "    \n",
    "    def enhanced_dp_sum(self):\n",
    "        #masking real space\n",
    "        blurred_bf = ndimage.gaussian_filter(self.bf.astype(np.float32), self.real_bg_sigma)\n",
    "        thresh_otsu_gaussian = filters.threshold_otsu(blurred_bf)\n",
    "        self.rs_mask = blurred_bf >= thresh_otsu_gaussian\n",
    "        \n",
    "        #taking diffraction space from masked real space\n",
    "        dp_mask = stim.mask_real_space(self.sp, self.rs_mask)\n",
    "        dp_mask_log = np.log1p(dp_mask)\n",
    "        \n",
    "        ### masking center\n",
    "        center_x, center_y = dp_mask_log.shape[0] / 2, dp_mask_log.shape[1] / 2\n",
    "        radius = 30\n",
    "        radius_edge = dp_mask_log.shape[0]-300\n",
    "        \n",
    "        # create grid of coordinates\n",
    "        y, x = np.ogrid[:dp_mask_log.shape[0], :dp_mask_log.shape[1]]\n",
    "        \n",
    "        # Create a circular mask\n",
    "        distance_from_center = np.sqrt((x - center_x)**2 + (y - center_y)**2)\n",
    "        circular_mask = distance_from_center <= radius\n",
    "        circular_mask_edge = distance_from_center >= radius_edge\n",
    "        \n",
    "        # Combine masks: Set the center and edge to 0\n",
    "        combined_mask = circular_mask | circular_mask_edge\n",
    "        \n",
    "        # Apply the combined mask to the array\n",
    "        dp_mask_log[combined_mask] = 0\n",
    "        \n",
    "        plt.imshow(dp_mask_log)\n",
    "        plt.show()\n",
    "    \n",
    "        return dp_mask_log\n",
    "    \n",
    "    def show_all_peaks(self,dp_log, blobs):\n",
    "        plt.imshow(dp_log, cmap='gray')\n",
    "        plt.title('Detected Blobs')\n",
    "        \n",
    "        # Overlay blobs on the image and annotate with intensity values\n",
    "        for blob in blobs:\n",
    "            y, x = blob[:2]\n",
    "            plt.scatter(x, y, color='red', s=30, marker='o', alpha=0.2)\n",
    "            intensity = dp_log[int(y), int(x)]\n",
    "            # plt.text(x, y, f'{intensity:.2f}', color='white', fontsize=8, ha='center', va='center')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    #function to find and store peaks from summed dp\n",
    "    def generate_all_dp_sum_non_zero(self):\n",
    "    \n",
    "        dp_log = self.enhanced_dp_sum()\n",
    "        \n",
    "        blurred_image = ndimage.gaussian_filter(dp_log.astype(np.float32), self.sigma)\n",
    "        blobs = ncempy.algo.peak_find.peakFind2D(blurred_image, self.threshold)\n",
    "        all_dp_sum = np.zeros(dp_log.shape)\n",
    "        \n",
    "        # Store intensity of each blob into main_labels if intensity is non-zero\n",
    "        for blob in blobs:\n",
    "            y, x = blob[:2]\n",
    "            intensity = dp_log[int(y), int(x)]\n",
    "            if intensity != 0:  # Only store if intensity is non-zero\n",
    "                all_dp_sum[int(y), int(x)] = intensity\n",
    "    \n",
    "        self.peak_locations = np.transpose(np.nonzero(all_dp_sum))\n",
    "    \n",
    "        self.show_all_peaks(dp_log, blobs)\n",
    "        \n",
    "        return self.peak_locations\n",
    "    \n",
    "    #segments real space by block_size, \n",
    "    #finds valid blocks by only keeping blocks that has atleast 2 peaks in dp\n",
    "    #create an array of peaks and dp for each corresponding real space indices\n",
    "    \n",
    "    def bf_grid_segment(self):\n",
    "        for i in range(self.num_blocks_x):\n",
    "            for j in range(self.num_blocks_y):\n",
    "                \n",
    "                #grab top left coordinates of block\n",
    "                x1, y1 = j * self.block_size, i * self.block_size\n",
    "            \n",
    "                #grab bottom right coordinates of block\n",
    "                x2, y2 = (j + 1) * self.block_size - 1, (i + 1) * self.block_size - 1\n",
    "            \n",
    "                #store coordinates\n",
    "                self.block_coordinates.append((x1, y1, x2, y2))\n",
    "\n",
    "                segment_mask = self.rs_mask[x1:x2,y1:y2]\n",
    "\n",
    "                if np.mean(segment_mask) >= self.mask_threshold:\n",
    "    \n",
    "                    #find dp for that specific block coordinate in real space bf\n",
    "                    dp = self.sp[x1:x2 + 1, y1:y2 + 1, :, :].sum(axis=(0, 1))\n",
    "                    dp_log = np.log1p(dp)\n",
    "                    self.valid_dp_logs.append((dp_log, i, j))\n",
    "    \n",
    "                # #peak finding for current diffraction space just to check if it's a background or not\n",
    "                # blurred_image = ndimage.gaussian_filter(dp_log.astype(np.float32), self.sigma)\n",
    "                # blobs = ncempy.algo.peak_find.peakFind2D(blurred_image, self.threshold)\n",
    "    \n",
    "                # #check if there are atleast 2 peak (ignores background)\n",
    "                # if len(blobs) >= 2:\n",
    "                #     #store valid block with it's corresponding dp and indices in real space\n",
    "                #     self.valid_dp_logs.append((dp_log, i, j))\n",
    "    \n",
    "    #check if a valid square block in real space is the edge of a cluster \n",
    "    #(valid block = a block in real space where it's dp has at least 2 peaks)\n",
    "    def is_at_edge(self, i, j):\n",
    "            self.num_blocks_x, self.num_blocks_y = self.block_validity.shape\n",
    "    \n",
    "            #for all valid blocks, check at the edge\n",
    "            if i > 0 and j > 0 and i < self.num_blocks_x - 1 and j < self.num_blocks_y - 1:\n",
    "                if not self.block_validity[i - 1, j] or not self.block_validity[i + 1, j] or not self.block_validity[i, j - 1] or not self.block_validity[i, j + 1]:\n",
    "                    return True\n",
    "            return False\n",
    "    \n",
    "    #calculate similarity by comparing current dp to summed dp and store features for clustering\n",
    "    \n",
    "    def features_similarity(self):\n",
    "    \n",
    "        #go through each square grid in real space that is valid (valid_dp_logs == has peaks)\n",
    "        #dp_log = diffraction space at that square grid\n",
    "        # i,j indices of that real space square grid\n",
    "        for idx, (dp_log, i, j) in enumerate(self.valid_dp_logs):\n",
    "    \n",
    "            #within that square grid, check all peak_locations from entire diffraction sum\n",
    "            for loc_idx, (y, x) in enumerate(self.peak_locations):\n",
    "    \n",
    "                #check if a peak exists within 11x11 square around the actual peak\n",
    "                half_size = self.peak_square_size // 2\n",
    "                \n",
    "                # 11x11 square boundary\n",
    "                start_y = max(y - half_size, 0)\n",
    "                end_y = min(y + half_size + 1, dp_log.shape[0])\n",
    "                start_x = max(x - half_size, 0)\n",
    "                end_x = min(x + half_size + 1, dp_log.shape[1])\n",
    "    \n",
    "                #threshold for what pixel intensity is a peak [default = 2]\n",
    "                if np.any(dp_log[start_y:end_y,start_x:end_x] >= self.peak_threshold):\n",
    "    \n",
    "                    #reset intensity value to 0 before storing\n",
    "                    intensity = 0\n",
    "    \n",
    "                    # Find the highest value in the 11x11 square peak then store as intensity\n",
    "                    intensity = np.max(dp_log[start_y:end_y,start_x:end_x])\n",
    "    \n",
    "                    # if self.is_at_edge(i, j):\n",
    "                    #     min_distance = float('inf')\n",
    "                    #     for other_block, other_i, other_j in self.valid_dp_logs:\n",
    "                    #         if (other_i, other_j) != (i, j):\n",
    "                    #             distance = np.sqrt((other_i - i) ** 2 + (other_j - j) ** 2)\n",
    "                    #             if distance < min_distance:\n",
    "                    #                 min_distance = distance\n",
    "                    #     #if so, add similarity points\n",
    "                    #     similarity *= self.edge_points\n",
    "                        \n",
    "                    self.features[idx, loc_idx] = intensity*self.intensity_weight\n",
    "                    # self.features[idx, -1] = similarity\n",
    "                        \n",
    "        self.features = np.array(self.features)\n",
    "    \n",
    "    #find the optimal number of clusters using the elbow method\n",
    "    def elbow_method(self):\n",
    "            distortions = []\n",
    "            K = range(2, self.max_k_clusters + 1)\n",
    "    \n",
    "            for k in K:\n",
    "                kmeans = KMeans(n_clusters=k, random_state=0, n_init=30)\n",
    "                kmeans.fit(self.features)\n",
    "                #collect all sum of squared distance for each cluster\n",
    "                distortions.append(kmeans.inertia_)\n",
    "    \n",
    "            #find 2nd derivative to find differences between them\n",
    "            # deltas = np.diff(distortions, 2)\n",
    "            # #find index where difference is at minimum - offset\n",
    "            # opt_index = np.argmin(deltas) - int(self.tangent_offset)\n",
    "            # opt_k = K[opt_index]\n",
    "\n",
    "            kn = KneeLocator(K, distortions, curve='convex', direction='decreasing')\n",
    "            opt_k = kn.knee\n",
    "    \n",
    "            #plot tangent line\n",
    "            plt.plot(K, distortions, 'bo-')\n",
    "            plt.xlabel('Number of Clusters')\n",
    "            plt.ylabel('Distortion (Inertia)')\n",
    "            plt.title('Elbow Method For finding n_clusters')\n",
    "            plt.axvline(x=opt_k, color='r', linestyle='--', label=f'Optimal k = {opt_k}')\n",
    "    \n",
    "            opt_index = opt_k - 2\n",
    "            slope = (distortions[opt_index + 1] - distortions[opt_index - 1]) / (K[opt_index + 1] - K[opt_index - 1])\n",
    "            intercept = distortions[opt_index] - slope * K[opt_index]\n",
    "    \n",
    "            tangent_offset_x = np.linspace(K[0], K[-1], 200)\n",
    "            tangent_offset_y = slope * tangent_offset_x + intercept\n",
    "    \n",
    "            plt.plot(tangent_offset_x, tangent_offset_y, 'g--', label='tangent_offset Line at Optimal k')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "    \n",
    "            return opt_k\n",
    "    \n",
    "    #creates and sorts clusters by color\n",
    "    def cluster_colored_blocks(self, cluster_labels):\n",
    "        \n",
    "        #init a set of colors for each unique cluster label\n",
    "        cluster_colors = plt.cm.hsv(np.linspace(0, 1, len(set(cluster_labels))))\n",
    "    \n",
    "        #init list to store legend handles for the plot.\n",
    "        legend_handles = []\n",
    "    \n",
    "        #init dictionary to keep track of colors already added to the legend.\n",
    "        added_colors = {}\n",
    "    \n",
    "        #init list to store coordinates of blocks in each cluster\n",
    "        cluster_boxes = [[] for _ in range(len(set(cluster_labels)))]\n",
    "\n",
    "        #init dictionary to store summed diffraction patterns for each cluster\n",
    "        cluster_sums = {label: np.zeros(self.sp.shape[2:]) for label in set(cluster_labels)}\n",
    "    \n",
    "        #group each self.valid_dp_logs by each cluster\n",
    "        for i, label in enumerate(cluster_labels):\n",
    "            if label not in self.clustered_data:\n",
    "                self.clustered_data[label] = []\n",
    "            self.clustered_data[label].append(self.valid_dp_logs[i])\n",
    "    \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(self.bf, cmap='gray')\n",
    "        plt.title('Valid Squares on BF Image with Clusters (K-Means)')\n",
    "    \n",
    "         # iterate over each cluster and its corresponding items, using an index for colors\n",
    "        for cluster_index, (cluster_label, cluster_items) in enumerate(self.clustered_data.items()):\n",
    "\n",
    "            # select a color from the colormap for the current cluster, go through colors if there are more clusters than colors\n",
    "            color = tuple(cluster_colors[cluster_index % len(cluster_colors)])\n",
    "\n",
    "            #toggle facecolor\n",
    "            facecolor = color if self.facecolor_visible else 'none'\n",
    "       \n",
    "    \n",
    "            if color not in added_colors:\n",
    "                # add a rectangle with the current color to the legend handles\n",
    "                legend_handles.append(Rectangle((0, 0), 1, 1, edgecolor=color, facecolor=facecolor, alpha=1, label=f'Cluster {cluster_label}'))\n",
    "                \n",
    "                # mark this color as added with its corresponding cluster label\n",
    "                added_colors[color] = cluster_label\n",
    "                \n",
    "            for dp_log, i, j in cluster_items:\n",
    "                x1, y1, x2, y2 = self.block_coordinates[i * self.num_blocks_y + j]\n",
    "    \n",
    "                # create a rectangle to for the block with the current cluster's color\n",
    "                square = Rectangle((y1, x1), self.block_size, self.block_size, edgecolor=color, facecolor=facecolor, alpha=1)\n",
    "                plt.gca().add_patch(square)\n",
    "                \n",
    "                # store the coordinates of the current block to the cluster's list of boxes\n",
    "                cluster_boxes[cluster_label].append((x1, y1, x2, y2))\n",
    "                \n",
    "                # sum diffraction pattern of each cluster \n",
    "                block_dp = self.sp[x1:x2 + 1, y1:y2 + 1, :, :].sum(axis=(0, 1))\n",
    "                cluster_sums[cluster_label] += block_dp\n",
    "                \n",
    "        \n",
    "        # filter out any empty clusters\n",
    "        cluster_boxes = [boxes for boxes in cluster_boxes if boxes]\n",
    "        \n",
    "        # Sort the legend handles by cluster label (numerically)\n",
    "        legend_handles = sorted(legend_handles, key=lambda x: int(x.get_label().split()[1]))\n",
    "        plt.legend(handles=legend_handles, loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "        # plot the summed diffraction patterns for each cluster\n",
    "        for label, summed_dp in cluster_sums.items():\n",
    "            summed_dp_log = np.log1p(summed_dp)\n",
    "            plt.imshow(summed_dp_log, cmap='viridis')\n",
    "            plt.title(f'Summed Diffraction Space for Cluster {label}')\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "    \n",
    "    def main(self):\n",
    "\n",
    "        #generate summed dp of whole real space\n",
    "        self.peak_locations = self.generate_all_dp_sum_non_zero()\n",
    "        \n",
    "        #segments real space by block_size, \n",
    "        #finds valid blocks by only keeping blocks that has atleast 2 peaks in dp\n",
    "        #create an array of peaks and dp for each corresponding real space indices\n",
    "        self.bf_grid_segment()\n",
    "        \n",
    "        #checks if current dataset has no valid dp blocks\n",
    "        if len(self.valid_dp_logs) == 0:\n",
    "            raise ValueError(\"No valid blocks found\")\n",
    "    \n",
    "        # # Initialize features array with zeros [for some reason I get an error if I do not re-init]\n",
    "        self.features = np.zeros((len(self.valid_dp_logs), len(self.peak_locations) + 1))\n",
    "    \n",
    "        #calculate similarity and store features for clustering\n",
    "        self.features_similarity()\n",
    "    \n",
    "        #if user defined cluster number, else if 0, use optimal cluster from elbow method\n",
    "        if self.clusters:\n",
    "            best_k = int(self.clusters)\n",
    "        else:\n",
    "            best_k = self.elbow_method()\n",
    "    \n",
    "        #kmeans clustering\n",
    "        kmeans = KMeans(n_clusters=best_k, random_state=0, n_init=15)\n",
    "        cluster_labels = kmeans.fit_predict(self.features)\n",
    "\n",
    "        unique_clusters = np.unique(cluster_labels)\n",
    "\n",
    "        print(len(unique_clusters))\n",
    "    \n",
    "        #creates, sorts and shows clusters by color\n",
    "        self.cluster_colored_blocks(cluster_labels)\n",
    "\n",
    "        #save plot as png for gif\n",
    "        if self.is_gif:\n",
    "            Path('./gif/').mkdir(parents=True, exist_ok=True)\n",
    "            plt.savefig(os.path.join('./gif/', f'{self.gif_counter:03d}.png'))\n",
    "        plt.show()\n",
    "    \n",
    "        #to print indices of each real space block\n",
    "        if self.print_cluster_boxes:\n",
    "            print(\"Cluster Boxes:\")\n",
    "            for index, boxes in enumerate(cluster_boxes):\n",
    "                print(f\"Cluster {index}: {boxes}\")\n",
    "    \n",
    "        #to show dp of each block\n",
    "        if self.plot_dp_log:\n",
    "            for cluster_num, boxes in enumerate(cluster_boxes):\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    dp = self.sp[x1:x2 + 1, y1:y2 + 1, :, :].sum(axis=(0, 1))\n",
    "                    dp_log = np.log1p(dp)\n",
    "    \n",
    "                    plt.figure(figsize=(3, 3))\n",
    "                    plt.imshow(dp_log)\n",
    "                    plt.title(f\"Group {cluster_num}\")\n",
    "                    plt.colorbar()\n",
    "                    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df632e1-b1e3-4a43-ab1c-497f8a63b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Usage\n",
    "\n",
    "def update_plots(block_size, threshold, sigma, intensity_weight, clusters, peak_threshold, mask_threshold, facecolor_visible, real_bg_sigma):\n",
    "\n",
    "    h5_path = '/data.h5'\n",
    "    sp = stio.load_electron_counts(h5_path)\n",
    "    \n",
    "    #axis=(2,3) shows real space\n",
    "    bf = sp.sum(axis=(2,3))\n",
    "    segmenter = GridSegmentation(bf, sp, gif_counter=0, is_gif=False, block_size=block_size, clusters=clusters, max_k_clusters=15, real_bg_sigma=real_bg_sigma,\n",
    "                                 threshold=threshold, sigma=sigma, peak_threshold = peak_threshold, mask_threshold=mask_threshold, facecolor_visible=facecolor_visible,\n",
    "                                 edge_points=0,intensity_weight=intensity_weight, plot_dp_log=False, print_cluster_boxes=False)\n",
    "    segmenter.main()\n",
    "\n",
    "block_size_slider = widgets.IntSlider(value=11, min=5, max=20, step=1, description='Grid Size:', style={'description_width': 'initial'})\n",
    "threshold_slider = widgets.FloatSlider(value=0.2, min=0.1, max=1.0, step=0.01, description='Peak Finding Threshold:', style={'description_width': 'initial'})\n",
    "sigma_slider = widgets.FloatSlider(value=5, min=1, max=10, step=0.1, description='Peak Finding Sigma:', style={'description_width': 'initial'})\n",
    "real_bg_sigma_slider = widgets.FloatSlider(value=7, min=1, max=10, step=0.1, description='RS Background Sigma:', style={'description_width': 'initial'})\n",
    "intensity_slider = widgets.FloatSlider(value=1, min=1, max=1000, step=1, description='Intensity Weight:', style={'description_width': 'initial'})\n",
    "cluster_slider = widgets.FloatSlider(value=0, min=0, max=15, step=1, description='Num Clusters:', style={'description_width': 'initial'})\n",
    "peak_threshold_slider = widgets.FloatSlider(value=2, min=0, max=10, step=0.01, description='Peak Intensity Threshold:', style={'description_width': 'initial'})\n",
    "mask_threshold_silder = widgets.FloatSlider(value=0.5, min=0, max=1, step=0.01, description='Peak Percent Threshold:', style={'description_width': 'initial'})\n",
    "facecolor_visible_slider = widgets.FloatSlider(value=0, min=0, max=1, step=1, description='Facecolor:', style={'description_width': 'initial'})\n",
    "widgets.interact(update_plots, block_size=block_size_slider, real_bg_sigma=real_bg_sigma_slider,\n",
    "                 threshold=threshold_slider, sigma=sigma_slider, intensity_weight=intensity_slider, facecolor_visible=facecolor_visible_slider,\n",
    "                 clusters=cluster_slider, peak_threshold=peak_threshold_slider, mask_threshold=mask_threshold_silder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8a52d-cb99-440e-8b4f-13d75bc729e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
